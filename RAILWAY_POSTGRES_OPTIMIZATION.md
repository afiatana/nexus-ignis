# ðŸš€ Optimisasi PostgreSQL di Railway

Panduan lengkap untuk mengoptimalkan database PostgreSQL di Railway untuk performa maksimal.

---

## ðŸ“Š **1. Setting Dasar Railway Postgres**

### **A. Pilih Template yang Tepat**

Saat membuat Postgres service di Railway:
- âœ… Gunakan template **"PostgreSQL"** official dari Railway
- âœ… Jangan gunakan custom Docker image kecuali perlu
- Current version: PostgreSQL 15+ (Railway auto-update)

### **B. Environment Variables Essential**

Di Railway Postgres service, pastikan variables ini sudah ada (biasanya auto-generated):

```env
# Auto-generated oleh Railway (jangan edit manual)
POSTGRES_USER=postgres
POSTGRES_PASSWORD=<auto-generated>
POSTGRES_DB=railway
DATABASE_URL=postgresql://postgres:$POSTGRES_PASSWORD@$RAILWAY_PRIVATE_DOMAIN:5432/railway

# Variables tambahan untuk Railway
PGUSER=postgres
PGPASSWORD=$POSTGRES_PASSWORD
PGDATABASE=railway
```

**PENTING:** Jangan ubah variables di atas kecuali tahu apa yang Anda lakukan!

---

## âš¡ **2. Connection Pooling (PENTING!)**

Railway memiliki **connection limit**. Untuk project Anda yang menggunakan GitHub Actions + local dev, gunakan connection pooling.

### **Opsi A: Menggunakan PgBouncer (Recommended)**

Railway menyediakan built-in connection pooler. Gunakan connection URI khusus:

1. Di Railway Postgres service, lihat **Variables** tab
2. Cari atau buat variable: `DATABASE_URL_POOLED` atau gunakan endpoint pooler
3. Format connection string pooled:
   ```
   postgresql://postgres:password@postgres.railway.internal:5432/railway?pgbouncer=true
   ```

4. **Update di GitHub Secrets:**
   - Gunakan `DATABASE_URL` yang sudah ada (Railway automatically pools connections)
   - Atau gunakan `DATABASE_URL_POOLED` jika tersedia

### **Opsi B: Set Connection Limit di Code**

Update `db/connector.py` untuk menggunakan connection pooling:

```python
# Tambahkan parameter connection di connection string
DATABASE_URL = os.environ.get("DATABASE_URL")
# Pastikan max connections tidak melebihi Railway limit (default: 20)
```

Railway **free tier** limit:
- Max connections: **20 concurrent connections**
- Connection timeout: 60 detik

---

## ðŸ”§ **3. Optimisasi Performance PostgreSQL**

### **A. Index Optimization**

Pastikan index sudah optimal (sudah ada di `schema.sql`):

```sql
-- Full-text search index (sudah ada)
CREATE INDEX IF NOT EXISTS idx_archived_documents_search 
ON archived_documents 
USING GIN (to_tsvector('indonesian', cleaned_text));

-- Index tambahan untuk performa query
CREATE INDEX IF NOT EXISTS idx_archived_documents_url 
ON archived_documents (original_url);

CREATE INDEX IF NOT EXISTS idx_archived_documents_created 
ON archived_documents (created_at DESC);

CREATE INDEX IF NOT EXISTS idx_archived_documents_category 
ON archived_documents (category);

-- Composite index untuk query filtering
CREATE INDEX IF NOT EXISTS idx_archived_documents_category_created 
ON archived_documents (category, created_at DESC);
```

### **B. PostgreSQL Configuration (Advanced)**

Railway Postgres menggunakan config optimal by default, tapi Anda bisa customize via SQL:

```sql
-- Set work_mem untuk search queries yang lebih baik
ALTER DATABASE railway SET work_mem = '16MB';

-- Optimize for read-heavy workload
ALTER DATABASE railway SET random_page_cost = 1.1;

-- Better statistics untuk query planner
ALTER DATABASE railway SET default_statistics_target = 100;
```

âš ï¸ **Catatan:** Railway free tier mungkin override beberapa settings ini.

---

## ðŸ“ˆ **4. Resource Management**

### **Free Tier vs Paid Plans**

| Resource | Free Tier | Developer ($5/month) | Team ($20/month) |
|----------|-----------|---------------------|------------------|
| **RAM** | 512 MB | 1 GB | 2 GB |
| **CPU** | Shared | Shared | Dedicated |
| **Storage** | 1 GB | 5 GB | 10 GB |
| **Connections** | 20 | 40 | 100 |
| **Uptime** | Sleep after inactivity | Always on | Always on |

### **Rekomendasi untuk Project Anda:**

Untuk search engine dengan GitHub Actions daily scraping:

- **Development/Testing:** Free tier sudah cukup
- **Production (>1000 URLs):** Developer plan ($5/month)
- **High Traffic:** Team plan ($20/month)

---

## ðŸ”„ **5. Backup & Disaster Recovery**

### **Auto Backup di Railway**

Railway **TIDAK** otomatis backup di free tier!

#### **Setup Manual Backup:**

1. **Gunakan Railway CLI untuk backup:**
   ```bash
   railway login
   railway link [project-id]
   railway run pg_dump > backup_$(date +%Y%m%d).sql
   ```

2. **Automasi Backup via GitHub Actions:**

Create file `.github/workflows/db_backup.yml`:

```yaml
name: Weekly Database Backup

on:
  schedule:
    # Every Sunday at 3:00 AM WIB
    - cron: '0 20 * * 0'
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest
    steps:
      - name: Backup Database
        run: |
          pg_dump ${{ secrets.DATABASE_URL }} > backup_$(date +%Y%m%d).sql
      
      - name: Upload to GitHub
        uses: actions/upload-artifact@v3
        with:
          name: database-backup
          path: backup_*.sql
          retention-days: 30
```

3. **Atau gunakan cron job lokal:**
```bash
# Buat file backup.sh
#!/bin/bash
pg_dump [DATABASE_URL] > backup_$(date +%Y%m%d_%H%M%S).sql
```

---

## ðŸ“Š **6. Monitoring & Maintenance**

### **A. Monitor Resource Usage**

1. **Di Railway Dashboard:**
   - Klik Postgres service
   - Tab **"Metrics"** untuk lihat:
     - CPU usage
     - Memory usage
     - Disk usage
     - Network traffic

2. **Monitor Connection Count:**
```sql
SELECT count(*) as active_connections 
FROM pg_stat_activity 
WHERE datname = 'railway';
```

3. **Check Slow Queries:**
```sql
SELECT pid, now() - pg_stat_activity.query_start AS duration, query 
FROM pg_stat_activity 
WHERE state = 'active' 
  AND now() - pg_stat_activity.query_start > interval '5 seconds';
```

### **B. Database Maintenance**

Jalankan maintenance queries secara berkala:

```sql
-- Vacuum untuk cleanup dead rows (jalankan weekly)
VACUUM ANALYZE archived_documents;

-- Reindex untuk optimize index (jalankan monthly)
REINDEX TABLE archived_documents;

-- Check database size
SELECT pg_size_pretty(pg_database_size('railway')) as db_size;

-- Check table size
SELECT pg_size_pretty(pg_total_relation_size('archived_documents')) as table_size;
```

### **C. Setup Maintenance Script**

Create `db/maintenance.sql`:

```sql
-- Weekly Maintenance Script
-- Run this every week untuk performa optimal

-- 1. Analyze table statistics
ANALYZE archived_documents;

-- 2. Vacuum dead rows
VACUUM (VERBOSE, ANALYZE) archived_documents;

-- 3. Check for bloat
SELECT schemaname, tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- 4. Check index usage
SELECT schemaname, tablename, indexname, idx_scan
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
ORDER BY idx_scan ASC;
```

---

## ðŸŽ¯ **7. Best Practices untuk Search Engine**

### **A. Partitioning (Untuk Data Besar)**

Jika database >10,000 URLs, pertimbangkan partitioning by date:

```sql
-- Buat parent table
CREATE TABLE archived_documents_partitioned (
    LIKE archived_documents INCLUDING ALL
) PARTITION BY RANGE (created_at);

-- Buat partitions per bulan
CREATE TABLE archived_documents_2024_12 PARTITION OF archived_documents_partitioned
    FOR VALUES FROM ('2024-12-01') TO ('2025-01-01');

CREATE TABLE archived_documents_2025_01 PARTITION OF archived_documents_partitioned
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
```

### **B. Archive Old Data**

Untuk data lama (>6 bulan):

```sql
-- Buat archive table
CREATE TABLE archived_documents_archive AS 
SELECT * FROM archived_documents 
WHERE created_at < NOW() - INTERVAL '6 months';

-- Delete dari main table
DELETE FROM archived_documents 
WHERE created_at < NOW() - INTERVAL '6 months';

-- Vacuum untuk reclaim space
VACUUM FULL archived_documents;
```

### **C. Query Optimization Tips**

```sql
-- GOOD: Gunakan index yang ada
SELECT * FROM archived_documents 
WHERE category = 'Code' 
ORDER BY created_at DESC 
LIMIT 100;

-- BAD: LIKE dengan % di awal (tidak pakai index)
SELECT * FROM archived_documents 
WHERE cleaned_text LIKE '%keyword%';

-- GOOD: Gunakan full-text search
SELECT * FROM archived_documents 
WHERE to_tsvector('indonesian', cleaned_text) @@ to_tsquery('indonesian', 'keyword')
LIMIT 100;
```

---

## ðŸ”’ **8. Security Best Practices**

### **A. Connection Security**

```python
# Gunakan SSL untuk production
import psycopg2

conn = psycopg2.connect(
    DATABASE_URL,
    sslmode='require'  # Force SSL
)
```

### **B. Limit User Permissions**

Jika membuat user tambahan:

```sql
-- Buat read-only user untuk analytics
CREATE USER analytics WITH PASSWORD 'secure_password';
GRANT CONNECT ON DATABASE railway TO analytics;
GRANT SELECT ON archived_documents TO analytics;

-- Buat write user untuk scraper
CREATE USER scraper WITH PASSWORD 'secure_password';
GRANT SELECT, INSERT, UPDATE ON archived_documents TO scraper;
```

### **C. Environment Variable Management**

```bash
# Di Railway, set variable tambahan untuk security
PGSSLMODE=require
PGCONNECT_TIMEOUT=10
```

---

## ðŸ“‹ **9. Checklist Optimisasi**

### **Setup Awal** âœ…
- [ ] PostgreSQL service sudah running di Railway
- [ ] Schema `db/schema.sql` sudah dijalankan
- [ ] Index untuk full-text search sudah dibuat
- [ ] DATABASE_URL sudah ditambahkan ke GitHub Secrets

### **Performance** âš¡
- [ ] Connection pooling dikonfigurasi (jika perlu)
- [ ] Index tambahan dibuat (url, created_at, category)
- [ ] Query optimization diterapkan di code
- [ ] Monitoring metrics di Railway dashboard

### **Maintenance** ðŸ”§
- [ ] Backup strategy sudah ada (manual atau automated)
- [ ] Weekly VACUUM scheduled
- [ ] Monthly REINDEX scheduled
- [ ] Disk space monitoring aktif

### **Security** ðŸ”’
- [ ] SSL enabled untuk connections
- [ ] DATABASE_URL tidak hardcoded di code
- [ ] Secrets management proper (GitHub Secrets)
- [ ] User permissions limited (jika applicable)

---

## ðŸš¨ **10. Troubleshooting Common Issues**

### **Issue: "Too many connections"**

```bash
Solusi:
1. Close unused connections di Railway Metrics
2. Gunakan connection pooling
3. Upgrade ke paid plan untuk more connections
```

### **Issue: "Disk full"**

```sql
-- Check disk usage
SELECT pg_size_pretty(pg_database_size('railway'));

-- Cleanup:
VACUUM FULL;

-- Archive old data atau upgrade storage
```

### **Issue: "Slow queries"**

```sql
-- Enable query logging
ALTER DATABASE railway SET log_min_duration_statement = 1000; -- log queries >1s

-- Analyze slow query
EXPLAIN ANALYZE SELECT ...;

-- Add missing index jika perlu
```

### **Issue: "Service keeps sleeping (Free tier)"**

```bash
Solusi:
1. Upgrade ke Developer plan ($5/month) untuk always-on
2. Atau set up "keep-alive" ping setiap 10 menit
3. Accept bahwa free tier akan sleep after 5 min inactivity
```

---

## ðŸ’¡ **Rekomendasi untuk Project Anda**

Berdasarkan search engine project Anda dengan daily scraping:

### **Immediate (Langsung Lakukan):**
1. âœ… Jalankan semua queries di section "Index Optimization"
2. âœ… Setup monitoring untuk disk usage
3. âœ… Tambahkan index untuk `original_url`, `created_at`, `category`

### **Short-term (Dalam 1-2 Minggu):**
1. â³ Setup backup automation (GitHub Actions atau cron)
2. â³ Monitor query performance
3. â³ Optimize slow queries jika ada

### **Long-term (Jika Data Bertambah Banyak):**
1. ðŸ”® Pertimbangkan partitioning by date
2. ðŸ”® Archive old data (>6 months)
3. ðŸ”® Upgrade ke paid plan jika hit limits

### **Budget Recommendation:**
- **0-1000 URLs:** Free tier âœ…
- **1000-10,000 URLs:** Developer plan ($5/month) ðŸ’°
- **10,000+ URLs:** Team plan ($20/month) ðŸ’°ðŸ’°

---

**Setup optimal selesai! Database Anda siap untuk production! ðŸš€**
